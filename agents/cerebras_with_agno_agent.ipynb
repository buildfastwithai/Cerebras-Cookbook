{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJDuepU5MI0o"
      },
      "source": [
        "\n",
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSkez75fZoo82SccEXRMVRlj9sZsQifRUhURQ&s\" width=\"200\">\n",
        "<img src=\"https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/fc52752016ff487da8e4686a2b7fcb6d\" width=\"120\">\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1cbX10xhxtjENyJJGtVFupeiLqP4cr3t8?usp=sharing)\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>Cerebras Inference</h2>\n",
        "  <p>Cerebras Systems builds the world's largest computer chip - the Wafer Scale Engine (WSE) - designed specifically for AI workloads. This cookbook provides comprehensive examples, tutorials, and best practices for developing and deploying AI models using Cerebras infrastructure, including both training on WSE clusters and fast inference via Cerebras Cloud.</p>\n",
        "\n",
        "</div>\n",
        "</div>\n",
        "\n",
        "## What is Agno?\n",
        "\n",
        "Agno is a lightweight library for building agents with memory, knowledge, tools, and reasoning capabilities. It's model-agnostic, allowing you to connect to 23+ model providers without lock-in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z7V2CqUcjLX"
      },
      "source": [
        "#Cerebras with Agno Agent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nGbS8KyN9X2"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A Cerebras API key (Get yours at [Cerebras Cloud](https://cloud.cerebras.ai/))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz_y_cxUMI0q"
      },
      "source": [
        "## Setup and Installation\n",
        "\n",
        "First, let's install the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhXf1TuTMI0r",
        "outputId": "04e44941-c691-4931-a70d-afe7b256a714"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai agno ddgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB0lpP8yMI0s"
      },
      "source": [
        "## Setting up Environment Variables\n",
        "\n",
        "You'll need to set up your API keys. For security reasons, it's best to use environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HgW6CkKMI0s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"CEREBRAS_API_KEY\"] = userdata.get(\"CEREBRAS_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Nh9jvVMI0t"
      },
      "source": [
        "## Basic Usage of Cerebras with OpenAI Client\n",
        "\n",
        "Let's first see how to use Cerebras with the standard OpenAI client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh4wyQhVMI0t",
        "outputId": "ede67ceb-43a3-4da9-9e25-3ab4479857a3"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url='https://api.cerebras.ai/v1',\n",
        "    api_key=os.environ[\"CEREBRAS_API_KEY\"]\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3.3-70b\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that specializes in AI and machine learning.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain the concept of neural networks in simple terms.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6uet0F3MI0t"
      },
      "source": [
        "## Testing Different Cerebras Models\n",
        "\n",
        "Cerebras offers multiple models. Let's test with different models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW6wuvE_MI0t",
        "outputId": "6c27c572-24c8-4d87-8cef-266b6c6fb5fa"
      },
      "outputs": [],
      "source": [
        "models = [\"llama3.3-70b\", \"qwen-3-coder-480b\", \"gpt-oss-120b\"]\n",
        "\n",
        "for model in models:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Testing model: {model}\")\n",
        "    print(f\"{'='*50}\\n\")\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
        "        ],\n",
        "        max_tokens=50\n",
        "    )\n",
        "\n",
        "    print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsWFf94DMI0v"
      },
      "source": [
        "## Integrating Cerebras with Agno Agent\n",
        "\n",
        "Now, let's integrate Cerebras with Agno to create an intelligent agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958,
          "referenced_widgets": [
            "ec2686a3b4b34e248b0938e4a4407c87",
            "ca46839c69f443b0b6c8d3e214df40f0"
          ]
        },
        "id": "1Jd6Hz4yMI0v",
        "outputId": "ea273b29-e6d2-42b8-88ef-a2d468f8caee"
      },
      "outputs": [],
      "source": [
        "from agno.agent import Agent\n",
        "from agno.models.openai.like import OpenAILike\n",
        "\n",
        "cerebras_agent = Agent(\n",
        "    model=OpenAILike(\n",
        "        id=\"llama3.3-70b\",\n",
        "        api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
        "        base_url=\"https://api.cerebras.ai/v1\"\n",
        "    ),\n",
        "    description=\"You are a helpful AI assistant powered by Cerebras inference.\",\n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "cerebras_agent.print_response(\"Tell me about the benefits of fast inference in AI applications.\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w32PJztZMI0w"
      },
      "source": [
        "## Adding Tools to the Cerebras Agent\n",
        "\n",
        "Let's enhance our Cerebras agent by adding tools, such as web search capabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479,
          "referenced_widgets": [
            "bc788f439fca44949e0044553527002e",
            "70a8f914ddd545fb87303b144b26da21"
          ]
        },
        "id": "Mih1SGiSMI0w",
        "outputId": "843dee14-545b-4c1f-e17d-c05455277442"
      },
      "outputs": [],
      "source": [
        "from agno.tools.duckduckgo import DuckDuckGoTools\n",
        "\n",
        "cerebras_agent_with_tools = Agent(\n",
        "    model=OpenAILike(\n",
        "        id=\"llama3.3-70b\",\n",
        "        api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
        "        base_url=\"https://api.cerebras.ai/v1\"\n",
        "    ),\n",
        "    description=\"You are a helpful assistant with web search capabilities.\",\n",
        "    tools=[DuckDuckGoTools()],\n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "cerebras_agent_with_tools.print_response(\"What are the latest developments in Cerebras technology?\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc-8qsfyMI0x"
      },
      "source": [
        "## Creating a Research Agent with Reasoning\n",
        "\n",
        "Now, let's create a more advanced Cerebras agent that can handle research tasks with reasoning capabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f52666080622458bb4676ea717f5de21",
            "728e3346c9fb47c4bcd0fbc8496f02ca"
          ]
        },
        "id": "4nAZP3NQMI0x",
        "outputId": "c005fa6b-2409-4769-cc9b-7d40c1593401"
      },
      "outputs": [],
      "source": [
        "research_agent = Agent(\n",
        "    model=OpenAILike(\n",
        "        id=\"llama3.3-70b\",\n",
        "        api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
        "        base_url=\"https://api.cerebras.ai/v1\"\n",
        "    ),\n",
        "    description=\"You are a research assistant that can analyze complex topics and provide well-reasoned answers.\",\n",
        "    tools=[DuckDuckGoTools()],\n",
        "    instructions=[\n",
        "        \"Break down complex questions into smaller parts.\",\n",
        "        \"Use web search when you need current information.\",\n",
        "        \"Provide detailed, well-structured answers.\",\n",
        "        \"Cite your sources when using web search results.\"\n",
        "    ],\n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "research_agent.print_response(\n",
        "    \"Compare the performance of Cerebras inference with traditional GPU-based inference. What makes it faster?\",\n",
        "    stream=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbqq1AW6w4Sr"
      },
      "source": [
        "## Creating a Specialized Code Assistant Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7b7afea5a88c461ba33c4874660f3000",
            "49423fc8e3a047f6b2e3145ddf85bf0b"
          ]
        },
        "id": "K-OIIqksw4Sr",
        "outputId": "b55a9d65-5145-4527-bfbb-0639286022a0"
      },
      "outputs": [],
      "source": [
        "code_agent = Agent(\n",
        "    model=OpenAILike(\n",
        "        id=\"llama3.3-70b\",\n",
        "        api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
        "        base_url=\"https://api.cerebras.ai/v1\"\n",
        "    ),\n",
        "    description=\"You are an expert code assistant that helps with programming questions.\",\n",
        "    instructions=[\n",
        "        \"Provide clear, well-commented code examples.\",\n",
        "        \"Explain complex concepts step by step.\",\n",
        "        \"Follow best practices and coding standards.\",\n",
        "        \"Include error handling when appropriate.\"\n",
        "    ],\n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "code_agent.print_response(\n",
        "    \"Write a Python function that implements a binary search algorithm with detailed explanations.\",\n",
        "    stream=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOn3aI00w4Sr"
      },
      "source": [
        "## Creating a Multi-Agent System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bb3ae3a75b9b4fd68c228c20672de5c5",
            "4a63844d203840379e3b37ea4138a43d",
            "685a8f053b7f4b29a5afac3bc2283c91",
            "52143b6489c94b2a8920d7f1e09c37f2"
          ]
        },
        "id": "kKuHgHvTw4Sr",
        "outputId": "2ae084d8-8318-4a6f-d227-e4016d53ba0d"
      },
      "outputs": [],
      "source": [
        "general_agent = Agent(\n",
        "    model=OpenAILike(\n",
        "        id=\"llama3.3-70b\",\n",
        "        api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
        "        base_url=\"https://api.cerebras.ai/v1\"\n",
        "    ),\n",
        "    name=\"General Assistant\",\n",
        "    description=\"General purpose assistant\",\n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "technical_agent = Agent(\n",
        "    model=OpenAILike(\n",
        "        id=\"llama3.3-70b\",\n",
        "        api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
        "        base_url=\"https://api.cerebras.ai/v1\"\n",
        "    ),\n",
        "    name=\"Technical Expert\",\n",
        "    description=\"Expert in technical topics and programming\",\n",
        "    tools=[DuckDuckGoTools()],\n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "print(\"General Agent Response:\")\n",
        "general_agent.print_response(\"What is machine learning?\", stream=True)\n",
        "\n",
        "print(\"\\n\\nTechnical Agent Response:\")\n",
        "technical_agent.print_response(\"What is machine learning?\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0bMj2ifw4Sr"
      },
      "source": [
        "## Creating a Conversational Agent with Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649,
          "referenced_widgets": [
            "e1711e16299040c09e81d5de2ab9ae04",
            "5055d623be2a40c6abe0c47b6c16b67d",
            "bc393c22cb9a4207ac63ca21828dfe84",
            "ecda9fcfa4e24e7197331120f088a3ac"
          ]
        },
        "id": "gWFmMjV0w4Sr",
        "outputId": "9f037efd-f916-4db3-d422-064577931d98"
      },
      "outputs": [],
      "source": [
        "conversational_agent = Agent(\n",
        "    model=OpenAILike(\n",
        "        id=\"llama3.3-70b\",\n",
        "        api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
        "        base_url=\"https://api.cerebras.ai/v1\"\n",
        "    ),\n",
        "    description=\"You are a friendly conversational assistant that remembers context.\",\n",
        "    markdown=True,\n",
        ")\n",
        "\n",
        "print(\"First interaction:\")\n",
        "conversational_agent.print_response(\"My name is John and I'm learning about AI.\", stream=True)\n",
        "\n",
        "print(\"\\n\\nSecond interaction:\")\n",
        "conversational_agent.print_response(\"What's my name and what am I learning about?\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BJHFL9Mw4Ss"
      },
      "source": [
        "## Performance Comparison: Streaming vs Non-Streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919,
          "referenced_widgets": [
            "884e9a57b6734cb39b43f75cf16395fa",
            "b7d348e53b2341b78ccf0eebb419225f",
            "0eab11b9f0794deeb2c9f5fda05fc014",
            "d242472b57044b1599e1563aa7f929d9"
          ]
        },
        "id": "2cIPpnX9w4Ss",
        "outputId": "9e75422e-a3c4-4434-9185-67eaa2dcfae2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "test_agent = Agent(\n",
        "    model=OpenAILike(\n",
        "        id=\"llama3.3-70b\",\n",
        "        api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
        "        base_url=\"https://api.cerebras.ai/v1\"\n",
        "    ),\n",
        "    markdown=True\n",
        ")\n",
        "\n",
        "query = \"Explain quantum computing in 3 paragraphs.\"\n",
        "\n",
        "print(\"Non-streaming response:\")\n",
        "start_time = time.time()\n",
        "test_agent.print_response(query, stream=False)\n",
        "non_stream_time = time.time() - start_time\n",
        "print(f\"\\nTime taken: {non_stream_time:.2f} seconds\")\n",
        "\n",
        "print(\"\\n\\nStreaming response:\")\n",
        "start_time = time.time()\n",
        "test_agent.print_response(query, stream=True)\n",
        "stream_time = time.time() - start_time\n",
        "print(f\"\\nTime taken: {stream_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NSdHxPXMI0z"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've demonstrated how to use Cerebras models with the OpenAI client and integrate them with Agno to create intelligent agents. We've explored:\n",
        "\n",
        "1. Basic usage of Cerebras with the OpenAI client\n",
        "2. Testing different Cerebras models\n",
        "3. Creating a simple Cerebras agent with Agno\n",
        "4. Adding tools like web search to the Cerebras agent\n",
        "5. Building a research agent with reasoning capabilities\n",
        "6. Creating specialized agents (code assistant)\n",
        "7. Implementing multi-agent systems\n",
        "8. Building conversational agents with memory\n",
        "9. Performance comparison between streaming and non-streaming responses\n",
        "\n",
        "Cerebras's ultra-fast inference capabilities, combined with Agno's flexible agent framework, provide a powerful platform for building intelligent applications that can respond quickly and leverage various tools and knowledge sources."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}